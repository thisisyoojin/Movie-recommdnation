{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System\n",
    "\n",
    "### Part 1: Movie Embedding\n",
    "\n",
    "By using a link data between entities, I trained the embedding model to connect movies and find similarities between them.\n",
    "\n",
    "### 1-1. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load,preprocess and save data/model\n",
    "import json\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "#Build an embedding model\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, Reshape\n",
    "from keras.layers.merge import Dot\n",
    "\n",
    "#To build a recommendation system\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use 2 datasets to build this movie recommendation system.<br>\n",
    "First I needed a rating for 10,000 movies rated by 1,000 users.\n",
    "The data used for this model is not real data, but randomly generated by numpy module to show how to create collaborative filtering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/wp_movies_10k.ndjson') as fin:\n",
    "    movies = [json.loads(l) for l in fin]\n",
    "\n",
    "with open('data/rating.ndjson') as finn:\n",
    "    rates=[li.replace('\\n', '').split(',') for li in finn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220251, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df = pd.DataFrame(rates, columns=['movie_id', 'person_id', 'rating'])\n",
    "rating_df['movie_id'] = rating_df['movie_id'].apply(int)\n",
    "rating_df['person_id'] = rating_df['person_id'].apply(int)\n",
    "rating_df['rating'] = rating_df['rating'].apply(float)\n",
    "\n",
    "rating_df = rating_df.groupby(['person_id', 'movie_id']).agg(np.mean)\n",
    "rating_full_df = rating_df.reset_index()\n",
    "rating_full_df.shape\n",
    "\n",
    "del rating_df\n",
    "\n",
    "rating_full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = np.asarray(rating_full_df['rating'])\n",
    "norm = rating / np.linalg.norm(rating)\n",
    "rating_full_df['rating_norm'] = norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Build the Embedding Model\n",
    "\n",
    "By using Counter, I sorted links to screen meaningful links. <br>\n",
    "After sorting data, I created a tuple (link index, movie index) and feed the Embedding model with negative sampling to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rotten Tomatoes', 9393),\n",
       " ('Category:English-language films', 5882),\n",
       " ('Category:American films', 5867)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_counts = Counter()\n",
    "for movie in movies:\n",
    "    link_counts.update(movie[2])\n",
    "link_counts.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671403"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_links = [link for link, c in link_counts.items() if c >= 3]\n",
    "link_to_idx = {link:idx for idx, link in enumerate(top_links)}\n",
    "\n",
    "movie_to_idx = {movie[0]:idx for idx, movie in enumerate(movies)}\n",
    "idx_to_movie = [movie[0] for movie in movies]\n",
    "\n",
    "pairs=[]\n",
    "\n",
    "for movie in movies:\n",
    "    pairs.extend((link_to_idx[link], movie_to_idx[movie[0]]) \n",
    "                 for link in movie[2] \n",
    "                 if link in link_to_idx)\n",
    "\n",
    "pairs_set = set(pairs)\n",
    "len(pairs_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "link (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "link_embedding (Embedding)      (None, 1, 30)        2007390     link[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "movie_embedding (Embedding)     (None, 1, 30)        300000      movie[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_product (Dot)               (None, 1, 1)         0           link_embedding[0][0]             \n",
      "                                                                 movie_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1)            0           dot_product[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 2,307,390\n",
      "Trainable params: 2,307,390\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def movie_embedding_model(embedding_size=30):\n",
    "    \n",
    "    link = Input(name='link', shape=(1,))\n",
    "    movie = Input(name='movie', shape=(1,))\n",
    "    \n",
    "    link_embedding = Embedding(name='link_embedding', \n",
    "                               input_dim=len(top_links), \n",
    "                               output_dim=embedding_size)(link)\n",
    "    \n",
    "    movie_embedding = Embedding(name='movie_embedding',\n",
    "                               input_dim=len(movie_to_idx),\n",
    "                               output_dim=embedding_size)(movie)\n",
    "    \n",
    "    dot=Dot(name='dot_product', normalize=True, axes=2)([link_embedding, movie_embedding])\n",
    "    \n",
    "    merged = Reshape((1,))(dot)\n",
    "    \n",
    "    model=Model(inputs=[link, movie], outputs=[merged])\n",
    "    \n",
    "    model.compile(optimizer='nadam', loss='mse')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = movie_embedding_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchifier(pairs, positive_samples=50, negative_ratio=5):\n",
    "    batch_size = positive_samples * (1+negative_ratio)\n",
    "    batch=np.zeros((batch_size, 3))\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        for idx, (link_id, movie_id) in enumerate(random.sample(pairs, positive_samples)):\n",
    "            batch[idx,:] = (link_id, movie_id, 1)\n",
    "        idx = positive_samples\n",
    "        \n",
    "        while idx < batch_size:\n",
    "            movie_id = random.randrange(len(movie_to_idx))\n",
    "            link_id = random.randrange(len(top_links))\n",
    "            \n",
    "            if not (link_id, movie_id) in pairs_set:\n",
    "                batch[idx,:] = (link_id, movie_id, -1)\n",
    "                idx += 1\n",
    "        \n",
    "        np.random.shuffle(batch)\n",
    "        yield {'link':batch[:,0], 'movie':batch[:,1]}, batch[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\thisi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/5\n",
      "1854/1854 [==============================] - 75s 40ms/step - loss: 0.3794\n",
      "Epoch 2/5\n",
      "1854/1854 [==============================] - 75s 40ms/step - loss: 0.2282\n",
      "Epoch 3/5\n",
      "1854/1854 [==============================] - 74s 40ms/step - loss: 0.2226\n",
      "Epoch 4/5\n",
      "1854/1854 [==============================] - 74s 40ms/step - loss: 0.2202\n",
      "Epoch 5/5\n",
      "1854/1854 [==============================] - 74s 40ms/step - loss: 0.2186\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(batchifier(pairs, positive_samples=512, negative_ratio=10), epochs=5,\n",
    "                   steps_per_epoch= len(pairs)//512)\n",
    "\n",
    "with open('embedding_movie_model.pkl', 'wb') as fout:\n",
    "    pickle.dump(model, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the weights from the embedding layer and normalising them to create the \n",
    " item profile (movie-to-features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = model.get_layer('movie_embedding')\n",
    "movie_weights = movie.get_weights()[0]\n",
    "\n",
    "norm_per_movie = np.linalg.norm(movie_weights, axis=1)\n",
    "normalized_movies = (movie_weights.T / norm_per_movie).T\n",
    "normalized_movies.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
